{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078554f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f861e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scaling Group Inference for Diverse and High-Quality Generation\n",
      "Authors: ['Gaurav Parmar', 'Or Patashnik', 'Daniil Ostashev', 'Kuan-Chieh Wang', 'Kfir Aberman', 'Srinivasa Narasimhan', 'Jun-Yan Zhu']\n",
      "Published: 2025-08-21 17:59:57+00:00\n",
      "URL: http://arxiv.org/abs/2508.15773v1\n",
      "Abstract: Generative models typically sample outputs independently, and recent\n",
      "inference-time guidance and scaling algorithms focus on improving the quality\n",
      "of individual samples. However, in real-world applications, users are often\n",
      "presented with a set of multiple images (e.g., 4-8) for each prompt, where\n",
      "independent sampling tends to lead to redundant results, limiting user choices\n",
      "and hindering idea exploration. In this work, we introduce a scalable group\n",
      "inference method that improves both the diversity and quality of a group of\n",
      "samples. We formulate group inference as a quadratic integer assignment\n",
      "problem: candidate outputs are modeled as graph nodes, and a subset is selected\n",
      "to optimize sample quality (unary term) while maximizing group diversity\n",
      "(binary term). To substantially improve runtime efficiency, we progressively\n",
      "prune the candidate set using intermediate predictions, allowing our method to\n",
      "scale up to large candidate sets. Extensive experiments show that our method\n",
      "significantly improves group diversity and quality compared to independent\n",
      "sampling baselines and recent inference algorithms. Our framework generalizes\n",
      "across a wide range of tasks, including text-to-image, image-to-image, image\n",
      "prompting, and video generation, enabling generative models to treat multiple\n",
      "outputs as cohesive groups rather than independent samples.\n",
      "Title: ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling\n",
      "Authors: ['Jinhyung Park', 'Javier Romero', 'Shunsuke Saito', 'Fabian Prada', 'Takaaki Shiratori', 'Yichen Xu', 'Federica Bogo', 'Shoou-I Yu', 'Kris Kitani', 'Rawal Khirodkar']\n",
      "Published: 2025-08-21 17:58:56+00:00\n",
      "URL: http://arxiv.org/abs/2508.15767v1\n",
      "Abstract: Parametric body models offer expressive 3D representation of humans across a\n",
      "wide range of poses, shapes, and facial expressions, typically derived by\n",
      "learning a basis over registered 3D meshes. However, existing human mesh\n",
      "modeling approaches struggle to capture detailed variations across diverse body\n",
      "poses and shapes, largely due to limited training data diversity and\n",
      "restrictive modeling assumptions. Moreover, the common paradigm first optimizes\n",
      "the external body surface using a linear basis, then regresses internal\n",
      "skeletal joints from surface vertices. This approach introduces problematic\n",
      "dependencies between internal skeleton and outer soft tissue, limiting direct\n",
      "control over body height and bone lengths. To address these issues, we present\n",
      "ATLAS, a high-fidelity body model learned from 600k high-resolution scans\n",
      "captured using 240 synchronized cameras. Unlike previous methods, we explicitly\n",
      "decouple the shape and skeleton bases by grounding our mesh representation in\n",
      "the human skeleton. This decoupling enables enhanced shape expressivity,\n",
      "fine-grained customization of body attributes, and keypoint fitting independent\n",
      "of external soft-tissue characteristics. ATLAS outperforms existing methods by\n",
      "fitting unseen subjects in diverse poses more accurately, and quantitative\n",
      "evaluations show that our non-linear pose correctives more effectively capture\n",
      "complex poses compared to linear models.\n",
      "Title: Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO\n",
      "Authors: ['Jaeha Lee', 'Gio Huh', 'Ning Su', 'Tony Yue YU']\n",
      "Published: 2025-08-21 17:58:50+00:00\n",
      "URL: http://arxiv.org/abs/2508.15766v1\n",
      "Abstract: Recent efforts have extended the capabilities of transformers in logical\n",
      "reasoning and symbolic computations. In this work, we investigate their\n",
      "capacity for non-linear latent pattern discovery in the context of functional\n",
      "decomposition, focusing on the challenging algebraic task of multivariate\n",
      "polynomial decomposition. This problem, with widespread applications in science\n",
      "and engineering, is proved to be NP-hard, and demands both precision and\n",
      "insight. Our contributions are threefold: First, we develop a synthetic data\n",
      "generation pipeline providing fine-grained control over problem complexity.\n",
      "Second, we train transformer models via supervised learning and evaluate them\n",
      "across four key dimensions involving scaling behavior and generalizability.\n",
      "Third, we propose Beam Grouped Relative Policy Optimization (BGRPO), a\n",
      "rank-aware reinforcement learning method suitable for hard algebraic problems.\n",
      "Finetuning with BGRPO improves accuracy while reducing beam width by up to\n",
      "half, resulting in approximately 75% lower inference compute. Additionally, our\n",
      "model demonstrates competitive performance in polynomial simplification,\n",
      "outperforming Mathematica in various cases.\n",
      "Title: Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space\n",
      "Authors: ['Kiarash Kazari', 'Ezzeldin Shereen', 'György Dán']\n",
      "Published: 2025-08-21 17:58:36+00:00\n",
      "URL: http://arxiv.org/abs/2508.15764v1\n",
      "Abstract: We address the problem of detecting adversarial attacks against cooperative\n",
      "multi-agent reinforcement learning with continuous action space. We propose a\n",
      "decentralized detector that relies solely on the local observations of the\n",
      "agents and makes use of a statistical characterization of the normal behavior\n",
      "of observable agents. The proposed detector utilizes deep neural networks to\n",
      "approximate the normal behavior of agents as parametric multivariate Gaussian\n",
      "distributions. Based on the predicted density functions, we define a normality\n",
      "score and provide a characterization of its mean and variance. This\n",
      "characterization allows us to employ a two-sided CUSUM procedure for detecting\n",
      "deviations of the normality score from its mean, serving as a detector of\n",
      "anomalous behavior in real-time. We evaluate our scheme on various multi-agent\n",
      "PettingZoo benchmarks against different state-of-the-art attack methods, and\n",
      "our results demonstrate the effectiveness of our method in detecting impactful\n",
      "adversarial attacks. Particularly, it outperforms the discrete counterpart by\n",
      "achieving AUC-ROC scores of over 0.95 against the most impactful attacks in all\n",
      "evaluated environments.\n",
      "Title: Intern-S1: A Scientific Multimodal Foundation Model\n",
      "Authors: ['Lei Bai', 'Zhongrui Cai', 'Maosong Cao', 'Weihan Cao', 'Chiyu Chen', 'Haojiong Chen', 'Kai Chen', 'Pengcheng Chen', 'Ying Chen', 'Yongkang Chen', 'Yu Cheng', 'Yu Cheng', 'Pei Chu', 'Tao Chu', 'Erfei Cui', 'Ganqu Cui', 'Long Cui', 'Ziyun Cui', 'Nianchen Deng', 'Ning Ding', 'Nanqin Dong', 'Peijie Dong', 'Shihan Dou', 'Sinan Du', 'Haodong Duan', 'Caihua Fan', 'Ben Gao', 'Changjiang Gao', 'Jianfei Gao', 'Songyang Gao', 'Yang Gao', 'Zhangwei Gao', 'Jiaye Ge', 'Qiming Ge', 'Lixin Gu', 'Yuzhe Gu', 'Aijia Guo', 'Qipeng Guo', 'Xu Guo', 'Conghui He', 'Junjun He', 'Yili Hong', 'Siyuan Hou', 'Caiyu Hu', 'Hanglei Hu', 'Jucheng Hu', 'Ming Hu', 'Zhouqi Hua', 'Haian Huang', 'Junhao Huang', 'Xu Huang', 'Zixian Huang', 'Zhe Jiang', 'Lingkai Kong', 'Linyang Li', 'Peiji Li', 'Pengze Li', 'Shuaibin Li', 'Tianbin Li', 'Wei Li', 'Yuqiang Li', 'Dahua Lin', 'Junyao Lin', 'Tianyi Lin', 'Zhishan Lin', 'Hongwei Liu', 'Jiangning Liu', 'Jiyao Liu', 'Junnan Liu', 'Kai Liu', 'Kaiwen Liu', 'Kuikun Liu', 'Shichun Liu', 'Shudong Liu', 'Wei Liu', 'Xinyao Liu', 'Yuhong Liu', 'Zhan Liu', 'Yinquan Lu', 'Haijun Lv', 'Hongxia Lv', 'Huijie Lv', 'Qidang Lv', 'Ying Lv', 'Chengqi Lyu', 'Chenglong Ma', 'Jianpeng Ma', 'Ren Ma', 'Runmin Ma', 'Runyuan Ma', 'Xinzhu Ma', 'Yichuan Ma', 'Zihan Ma', 'Sixuan Mi', 'Junzhi Ning', 'Wenchang Ning', 'Xinle Pang', 'Jiahui Peng', 'Runyu Peng', 'Yu Qiao', 'Jiantao Qiu', 'Xiaoye Qu', 'Yuan Qu', 'Yuchen Ren', 'Fukai Shang', 'Wenqi Shao', 'Junhao Shen', 'Shuaike Shen', 'Chunfeng Song', 'Demin Song', 'Diping Song', 'Chenlin Su', 'Weijie Su', 'Weigao Sun', 'Yu Sun', 'Qian Tan', 'Cheng Tang', 'Huanze Tang', 'Kexian Tang', 'Shixiang Tang', 'Jian Tong', 'Aoran Wang', 'Bin Wang', 'Dong Wang', 'Lintao Wang', 'Rui Wang', 'Weiyun Wang', 'Wenhai Wang', 'Yi Wang', 'Ziyi Wang', 'Ling-I Wu', 'Wen Wu', 'Yue Wu', 'Zijian Wu', 'Linchen Xiao', 'Shuhao Xing', 'Chao Xu', 'Huihui Xu', 'Jun Xu', 'Ruiliang Xu', 'Wanghan Xu', 'GanLin Yang', 'Yuming Yang', 'Haochen Ye', 'Jin Ye', 'Shenglong Ye', 'Jia Yu', 'Jiashuo Yu', 'Jing Yu', 'Fei Yuan', 'Bo Zhang', 'Chao Zhang', 'Chen Zhang', 'Hongjie Zhang', 'Jin Zhang', 'Qiaosheng Zhang', 'Qiuyinzhe Zhang', 'Songyang Zhang', 'Taolin Zhang', 'Wenlong Zhang', 'Wenwei Zhang', 'Yechen Zhang', 'Ziyang Zhang', 'Haiteng Zhao', 'Qian Zhao', 'Xiangyu Zhao', 'Xiangyu Zhao', 'Bowen Zhou', 'Dongzhan Zhou', 'Peiheng Zhou', 'Yuhao Zhou', 'Yunhua Zhou', 'Dongsheng Zhu', 'Lin Zhu', 'Yicheng Zou']\n",
      "Published: 2025-08-21 17:58:00+00:00\n",
      "URL: http://arxiv.org/abs/2508.15763v1\n",
      "Abstract: In recent years, a plethora of open-source foundation models have emerged,\n",
      "achieving remarkable progress in some widely attended fields, with performance\n",
      "being quite close to that of closed-source models. However, in high-value but\n",
      "more challenging scientific professional fields, either the fields still rely\n",
      "on expert models, or the progress of general foundation models lags\n",
      "significantly compared to those in popular areas, far from sufficient for\n",
      "transforming scientific research and leaving substantial gap between\n",
      "open-source models and closed-source models in these scientific domains. To\n",
      "mitigate this gap and explore a step further toward Artificial General\n",
      "Intelligence (AGI), we introduce Intern-S1, a specialized generalist equipped\n",
      "with general understanding and reasoning capabilities with expertise to analyze\n",
      "multiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE)\n",
      "model with 28 billion activated parameters and 241 billion total parameters,\n",
      "continually pre-trained on 5T tokens, including over 2.5T tokens from\n",
      "scientific domains. In the post-training stage, Intern-S1 undergoes offline and\n",
      "then online reinforcement learning (RL) in InternBootCamp, where we propose\n",
      "Mixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks\n",
      "simultaneously. Through integrated innovations in algorithms, data, and\n",
      "training systems, Intern-S1 achieved top-tier performance in online RL\n",
      "training.On comprehensive evaluation benchmarks, Intern-S1 demonstrates\n",
      "competitive performance on general reasoning tasks among open-source models and\n",
      "significantly outperforms open-source models in scientific domains, surpassing\n",
      "closed-source state-of-the-art models in professional tasks, such as molecular\n",
      "synthesis planning, reaction condition prediction, predicting thermodynamic\n",
      "stabilities for crystals. Our models are available at\n",
      "https://huggingface.co/internlm/Intern-S1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = arxiv.Client()\n",
    "\n",
    "search = arxiv.Search(\n",
    "    query=\"machine learning\",\n",
    "    max_results=5,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "for result in results:\n",
    "    print(\"Title:\", result.title)\n",
    "    print(\"Authors:\", [author.name for author in result.authors])\n",
    "    print(\"Published:\", result.published)\n",
    "    print(\"URL:\", result.entry_id)\n",
    "    print(\"Abstract:\", result.summary[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df420b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
